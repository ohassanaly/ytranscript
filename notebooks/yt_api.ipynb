{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56dd392d-1c36-4f50-a13a-073fe8daf78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.67.198.11\n"
     ]
    }
   ],
   "source": [
    "#fast chekc to see if IP matches \n",
    "import requests\n",
    "print(requests.get(\"https://api.ipify.org\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd306d5-6a13-4d84-9e40-1a84440895f2",
   "metadata": {},
   "source": [
    "If the video has an available transcript, retrieves the full transcript text using youtube_transcript_api,\n",
    "otherwise, returns the raised exception if no transcript available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5efddde-bd74-400f-8a0a-418d0e917bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad787c6-7b08-4fb5-b3ec-6c71fbb60c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\",\n",
    "    filename=\"yt_api.log\",\n",
    "    filemode=\"a\",  # append\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e313d84f-b28c-4076-94de-ad0c3066884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_url = \"https://www.youtube.com/watch?v=GuM6dQGRFyQ\"\n",
    "# video_url = \"https://www.youtube.com/watch?v=-hkEzwaY754\"\n",
    "# video_url = \"https://www.youtube.com/watch?v=HhzpDM36Pzg\"\n",
    "video_url = \"https://www.youtube.com/watch?v=01rldii7b_Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1baa9b-6b2a-4ab1-9b72-e646e9d9e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_video_id(url: str) -> str | None:\n",
    "    parsed = urlparse(url)\n",
    "\n",
    "    # youtu.be/<id>\n",
    "    if parsed.netloc in (\"youtu.be\", \"www.youtu.be\"):\n",
    "        return parsed.path.lstrip(\"/\")\n",
    "\n",
    "    # youtube.com/*\n",
    "    if \"youtube.com\" in parsed.netloc:\n",
    "        # watch?v=<id>\n",
    "        if parsed.path == \"/watch\":\n",
    "            return parse_qs(parsed.query).get(\"v\", [None])[0]\n",
    "\n",
    "        # /embed/<id>, /shorts/<id>\n",
    "        parts = parsed.path.split(\"/\")\n",
    "        if len(parts) >= 3 and parts[1] in {\"embed\", \"shorts\"}:\n",
    "            return parts[2]\n",
    "\n",
    "    return None\n",
    "\n",
    "def retrieve_video_transcript(video_url:str) -> str:\n",
    "    video_id = get_youtube_video_id(video_url)\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    full_text=\"\"\n",
    "    try : \n",
    "        fetched_transcript = ytt_api.fetch(video_id)\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Failed to fetch transcript for video_url=%s\",\n",
    "            video_url,\n",
    "        )\n",
    "        return(\"\")\n",
    "    for snippet in fetched_transcript.snippets:\n",
    "        full_text+= snippet.text + \" \"\n",
    "    return(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e47db1b-c77c-4d54-ac8d-734552f6f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = retrieve_video_transcript(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867a153b-4334-422d-9f9c-b42a33e19341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today we're going to talk about the latest innovations made available through the C3 Agentic AI platform to help developers onboard and build, deploy, and operate applications more quickly. Um, and as Jim Snobby talked about this morning, that's really the entire development team. Um, and so I'm joined today by my colleague Josh Prisbilo, who is the lead product manager on the C3 Agentic AI platform. Uh, and we're going to live demo some software to you today. My name is Jake Whitam. I lead developer experience at C3. Um, and thank you for joining us. So, one of the things that gets me inspired every year are the stories and the use cases that our customers are presenting on stage. And you know these are across supply network risk, inventory optimization, predictive maintenance, demand forecasting and more. And it's the C3 AI applications that are pre-built and extended in most cases to achieve these use cases or built you know from scratch on top of the C3 Aentic AI platform and we're achieving these use cases and the stories go that we've achieved speed and scale uh through the organization and when we talk about speed you know from a developer experience standpoint we talk about that day one of onboarding from that first time I open up C3AI studio and take training and scale uh in in in speed of deploying my first application. And you know today you heard Tom talk about a six six-month pilot and going from three to six months from you know discovering data to configuring your AI models to configuring application logic and UI and then scaling out not to just one facility or one area of your supply network but to the entire uh uh global fleet. And so what accelerates the speed and scale of these use cases? Well, first it's the pre-built AI applications, 131 today, that you can deploy out of the box, and they come preconfigured with the data pipelines, the AI models that you can fine-tune on your data, the application logic and alerting workflows, the application user interfaces that you can then configure. And then on top of that, they're taking advantage of the latest technologies available through the C3 Agentic AI platform that are pre-integrated, orchestrated, and made available to the entire development team. And so when Jeem snab talked about enabling the develop a development team on one platform, this collaboration is is key to make sure that the data sources that I'm working on as a data scientist are the same ones that are being uh worked on as you know by my colleague Josh um on the data engineering team. And so we're going to demo these workflows for you today. And this is all accelerated further by the you know great work of our industry partners uh Microsoft AWS Google um to provide the infrastructure services and tools um that the C3 AI agentic AI platform uh is deployed and with our applications on top of and so it's this core development team that we're focused on with developer experience. This is our passion and our mission is achieving self-sufficiency so that they can deploy uh build operate these AI applications very quickly. And so if you if you've worked with C3 before um you know that we've you know spent a lot of time uh interviewing customers. So we looked at over 2,000 SESAT surveys um inter customer interviews uh developer project reports and we listened to what the developers would would like to see in the platform next. And this is what we've heard. So from application engineering we heard things like more training around advanced UI courses. So we provide the foundational courses for uh UI development but give me more advanced courses so that when I want to use a native uh framework like react this is you know I can take an hour course on how to do that or let me have integrated co code and no co code tool development so that when Josh is using a noode tool uh it can seamlessly interact with a coding environment so that his the changes that Josh makes in his data pipelines in a noode interface can then show up in the codebase and I can make changes in code and that that seamlessly interoperates with his provide more troubleshooting doc and tools like on demand VS code directly from the browser to reduce setup time real-time developer sort support support so that if I don't have Josh or a data scientist sitting next to me I can go to a developer community and ask my question and get immediate responses application configuration guide so that you know from day one of deploying a new application like C3 reliability I know each step along the way and I can use agents to to help guide that approach. And from data science, we heard more things like resource monitoring. Let me as I scale up my GPUs for in large inferencing workloads, let me monitor those directly from C3AI studio so that I can better balance cost and performance of my overall environment. Um automated data transformations from from data engineers. Uh also data connectors, visual uh data load validation and visual visual object modeling. So a lot of the tasks that I might have otherwise carried out in my development environment like visual code extension previously are now available through a noode interface and that I can actually see those changes directly on the object model of C3 made available through C3AI studio. So since our product roadmap is largely driven by this customer feedback, we're actually including all of this in the latest version of the C3AI platform and we're going to show you this today. So today announcing new onboarding and developer experiences across the entire life cycle from training to documentation, expert support and visual developer tools made available through AI studio. In training, we have an entirely redesigned uh C3 AI Academy for online learning. And this is delivering 10 new courses and streamlined taskbased modular learning paths so that I can go in and take an hour of course training today, come back in a week and and learn some more specific skills. This is a trend and in a request that we've seen from our customers. We also launched in the last six months accelerators so that you can show up to these are uh two-day events where you can show up and work in a collaborative environment with our product managers, our solution architects and actually bring your own data and use case and we'll build an application you know using generative AI or C3 reliability on top of your data and in the two days you're presenting that back to your team and so this the combination of accelerators and online cing course courses that allow allowed me to be certified as a developer achieve you know help me on this path towards self-sufficiency as a development team and then as I want to go much deeper I have technical doc do documentation so we've delivered um now uh in context documentation as Adrian de demonstrated on stage this morning and we have a central uh developer portal that allows me to search through my documentation with over 10 new guides over 10 uh 20 total and much of this documentation you'll now find in context in your application or your developer tools so that I can now if I'm configuring a data pipeline I can click on help and actually get the context of the documentation there or interact with generative AI to ask the question about the context that I'm in for expert support we've rolled out an entirely redesigned C3AI community this is a 247 uh engagement form for all product questions and answers and what I can do is while I've gone while whether I'm in training or I'm in a deploy deployment. If I get stuck or I want tips on what to do next, I can go into the developer community, find the category like Genai or reliability or C3 Academy and ask a question there. And each team, each category is backed by the experts, the product managers, the engineering teams, the subject matter experts that are actually responsible for that area and can give me a response about what are the best practices or how to troubleshoot my code etc. And then visual developers tools uh tools available in AI studio including data fusion for noode integration validation of my uh data sources so that I can quickly map my data sources at my organization into the object models that are predefined uh in in the application. So we're going to show you this workflow right now. So on day one now I'm an application developer and I'm joined by my my colleague Josh and we're going to be collaborating as part of the development team to stand up a new application a pre-built app on predicted maintenance for wind turbines right and in this uh scenario I'm I'm coming in as a new developer and I this is day one in studio and what I have here is the front end of the AI the C3 Aentic AI platform. This is where I can come in and collaborate with my whole team. Get access to monitoring my apps and environments, set up release pipelines, which is a CI/CD process built in that lets me build the specific versions of my app and release that code after it's been tested. new administr administrative tools that allow me to view all of the compute resources so that I can see whether or not I have the correct GPU running and how much available resources are available and and who might be consuming those. And then we have my the application that we'll be be building this wind turbine predictive maintenance app and new application quick starts which are really uh pre-built tutorials that let me spit quickly spin up a uh a sandbox play around with a complete application try things out and then tear it down. This is part of the learning journey to help folks you know have a a hands-on experience during um training or just you know learning actually in the environment. And then we have uh resources on the right hand side from documentation community training where I can get started. And since I'm a new user and I want to demonstrate uh the new powerful C3 AAI Academy, let's go into uh training. So in the new C3 AI Academy, we have an entirely redef redesigned interface here with very easy to find learning paths. So on day one, I can get in and and start taking courses on digital transformation, platform administration, and architecture. And I can even view release highlight videos so that if I'm not in a presentation um with Josh at C3 Transform, I can always go and watch a mini video of Josh presenting the latest capabilities that are coming out in the new version of the platform. And so this is a portal that I can come back and watch and learn the latest that's available. Um and to to click on this new capability release highlights are going to be available for platform and applications. And as I go into platform release here I have uh version 8.5 of the C3 Agentic AI platform and some new capabilities from machine learning model operations uh code assistant in Jupiter uh application debugger etc. and and when I click in, I'll see that I get many feature videos that are about, you know, three to five minute long and get live demonstrations from the product owners. So, this is a great way to keep up to speed, make sure that as I'm upgrading, I can take advantage of the latest capabilities or see what's coming next. Well, let's jump back into academy because as a new developer on the team, I actually want to take a little bit of the machine learning because once Josh configures the data pipeline and maps the data into our application, the next step is I'm going to work on the feature engineering and building out the AI pipelines. So, I can see that the courses are now organized by learning paths. So, a learning path for data integration, machine learning, application development, and UI development. And what this allows me as I click into machine learning are modular courses where I don't need to start a, you know, a two-day long course and really complete all the, you know, starter steps to get to the the final step. I can take these in the order that I want. You know, certainly they're they're ordered in a certain way, but I can, you know, since I've already been part of a two-day accelerator program that C3 hosted, I've already taken some of the type system core architecture and I can jump right forward into some of the more advanced uh sections like feature engineering. Now getting starting with feature engineering, I will see that the courses contain a uh you know a series of videos and also uh deep technical labs where I'll get hands-on with the tool and get to try it out and debug and and work through problems on my own. So because these workshops are quite can get quite technical, I might and I'm potentially I'm working remotely. I don't have an application developer or data scientist by my side. I need a live training support uh agent and community to help me work through these problems. So I'm going to click into our community to get help. So C3 community is our customer engagement forum where developers can come and get questions about any C3 product and get immediate answers from those expert teams. So we have I land in C3 Academy category but we have categories across UI development, data integration, type system, generative AI, reliability and there are new categories coming out and each of these categories are backed by the expert teams at C3 and at our customers that can collaborate and help you work through the best practice um uh answers to your whether it's a coding problem or some best practice that you're looking for. And so since I'm working through the feature engineering course right now, I might come in and ask a question about um creating a uh a feature set which is a key step in the machine learning pipeline that allows me to take this, you know, transform the signals and my data into training data sets that then I can train my machine learning models. And a lot of the core IP is is is sometimes in this these feature definitions. So I want to go deep here. So I'll search creating a feature set and I can learn from others that have taken this course about here's here's a developer that ran into uh some trouble where you create your feature set. Now this developer comes in and and gives a lot of context about the code uh that ran well. this these are the steps that worked effectively and I was able to get through these steps and then I ran this code and then finally at the bottom I attempted to run this at as a parallelized job and I ran into this very specific error and somewhere buried in here is the error message and now as a subject m matter expert my colleague might come in here and kind of look through this and and you know within a half an hour or so can can write up a response but what's exciting about C3 community today is that We have our code assistant as the first responder to these technical questions. So C3 AAI code assistant is a fine-tuned LLM agentic AI system that is tuned on the entire C3 Agentic AI platform in the application code bases and thousands of additional best practice code examples so that it can specifically answer questions and give me actually code that I can then go add to my application. and it knows about all the documentation so that then it can give me more links. So it comes in and says based on the error message here's the issue. Here's what you should check in your code and here's the specific code that's tailored to your code example that will run. So this developer is then able to go and um copy that that code and lo and behold the AI assistant fixed my problem. Thanks for the quick response. And what's great about having a code assistant in a community like this is you have this human AI collaboration where a uh technical support trainer Rain also came in and added some additional context about what what what the developer might try to to unblock themselves. And then I can also because C3 code assistant provides the context the source attribution of the doc that the documentation I can go in and look even deeper and click into this feature story documentation so that if I want um I can really go and learn much more about feature feature engineering and this is all part of one of our 20 guides. This is a machine learning and data science guide that walks me through the entire life cycle. So I can go deep here. So with the combination of online training and accelerator workshops and then having live support from the community from the expert community as well as code assistant that's giving me live uh agentic AI responses to my coding questions I feel like I have the tools that I can achieve self-sufficiency and and work towards this path of now going and working on an application. So C3 AI code assistant is not just available in community today. We've made this available today for data scientists in Jupyter Lab, which is an ondemand service that that comes with C3AI studio, our Visual Studio Studio Code extension for application developers, so that developers can actually have a a private chat directly with the AI assistant and and ask um you know data science questions without leaving you know the privacy of their own their own closed environment there. So I can ask questions about training machine learning models if I'm a data scientist or setting up uh um you know developer uh data pipelines if I'm an application developer. So back into back into studio now Josh and I are going to start configuring this AI application and I'm going to click in and show you one more thing. We've also embedded C3 generative AI code assistant directly in studio. so that I can open this in the sidebar ask about um how do I configure CFKA? Um this is a a question that Josh might be looking at in the visual tools and the code assistant will provide me with an immediate response. So let me get started. I'm going to click on this application and then I'm going to hand off to my colleague Josh Prisbilo and we're part of this collaborative development team. He's going to work on integrating his source systems into the pre-built object model of this predictive maintenance application. Josh, thank you, Jake. Really exciting work with all the uh developer hub and technology transfer initiatives. So today we're going to first break down the most important elements of an agentic AI system. The large AI model by all means is the brains behind an agentic AI application and the agents. However, you can think of the integrations and connections into your business systems as the nervous system of your agentic AI applications, enabling the agents to reach into your systems, automate business processes, streamline workflows to simplify your business operations, drive efficiency and and and provide greater revenue. new opportunities. The data pipelines that feed from your data and application systems are the cardiovascular systems feeding the AI agents brain, the large AI models with the data it needs to make decisions and to thrive and and and uh become productive. Aentic AI systems need integrations to your business applications, Service Now, Workday, SAP, your ERPs, your CRM. We need integrations with your data warehouses, snowflakes, data bricks, big queries. We need integrations with real time streaming data from your IoT sensors in the field of your equipment in factories, in manufacturing plants. All of this data can be structured pabyte scale time series, unstructured images, text, PDFs, videos, 3D point cloud. An AI agentic AI platform needs an omnimodal data architecture to support all of these myriad types of integrations and data types. But an omnimodal dark data architecture is not sufficient in its own right. Businesses are rapidly evolving and so with it their data data sources constantly evolving data shape constantly evolving. If we need to feed these AI agents with all of this data, we need visual tools, simple tools to quickly onboard new data sources, validate existing data sources, change, manage, and orchestrate this multi-modal, omnimodal data architecture. Today, we're going to be introducing the visual tool that's up to this challenge. We refer to this as C3AI Studio Data Fusion. Jake and I have chosen C3I platform as our agentic AI platform for modernizing existing enterprise applications and developing net new AI agentic AI use cases to drive our business forward. We start from one of C3's pre-built applications. It has 90% of the logic we need for our particular use case. Tremendous accelerator. The first thing we're going to do is understand the application. We're going to d delve into the application data model. As developers, we wish to understand what does this object model look like? What are the types of data is it modeling? Thus understanding the workflows behind the application. And we can take a closer look at core objects, modeling facility, modeling manufacturer, and one of the ones that we're going to be talking about shortly is wind turbine events modeling time series data for our predictive maintenance use case. In this instance, we're doing predictive maintenance on wind wind turbine generators. Taking a zoom out, we can toggle on different information in our data model to help us onboard to it. For example, I'm going to provide the perspective of which of these objects do we intend or need to feed external data through into the object model versus which objects may be populated by downstream processes within the application such as an object capturing machine learning predictions which are downstream from the raw data that we're going to capture into these purple boxes. While I've been talking, Jake's been busy. Some of these objects when we look into them, we can preview data that's been loaded. Jake's been busy integrating some of the data for us. Can preview the data in the entities. However, panning over wind turbine measurement is the object that I'm going to be tasked with integrating unless Jake's done it for me. There's no data in this particular entity to preview because I have not yet configured the data pipeline. So, let's look at these data pipelines. Again, Jake's been busy. He's already populated some of the data pipelines. The data pipeline perspective complements the object model perspective by providing a very simple visual of my source data where my data is coming from from within my systems on the right which objects I am populating. So what are my targets and how the data is transformed from source into the target object. I can preview what these transforms look like. Again, Jake's been busy. These are fairly simple transforms that are simply mapping fields from source to target. Okay, so let's proceed with this application. I'm going to go to my data sources tab to which is the perspective I use to manage my data systems and sources. Jake's already configured two of the data sources. We've connected to a Google Cloud Storage bucket from which we have a couple of folders within the Google Cloud Storage from which we're integrating data whenever new new files arrive at a specific directory in that source system as defined here. It will be integrated transformed and integrated over to this target object. We've also configured our integration with our Snowflake data warehouse. Currently, I haven't connected Snowflake to anything. I will do so shortly. But remember, I'm after configuring that wind turbine measurement series, wind turbine measurement object, which is intended to capture time series data. And it's not just any time series data. What we're going to do now is integrate real time data from sensors that are live feeding through a Kafka broker. For for those of you um Kafka is a system that allows you to connect real-time sensor data and feed it as like a live data pipeline. And we're going to connect into that live data pipeline. Before I do so, I want to make sure my live data pipeline is actually turned on. otherwise. Okay. So, my wind turbine connector is on. So, through the Kafka portal, I'm inspecting my stream that I want to actually connect to and integrate with. And I can see new time series data arrive. Multiple messages arriving each second. So my stream is live. I next proceed to add data source. From here I can select from several of C3's connectors. I'm going to select Kuffka. Before this session, I created temporary credentials to my Kuffka broker that I'm actually going to use to connect to live. These credentials will be deactivated directly after this session. The credentials, bear with me. Okay, fingers crossed I copied all of those across. Oops. Going to click test connector connect connection. So in real practice, Kafka will typically be set up with several if not hundreds if not thousands of data streams that I can integrate in via this tool. I only need to establish this connection to Kuffka once. From there, I'm going to be able to explore all my data streams. Perfect. I'm hitting the Kafka broker. I'm going to call my connector transform Kuffka streaming data. And it can plate. We now have a live connection to Kafka. But that's not it. We haven't configured that pipeline yet. I'm going to select a stream to integrate into my system. I've got one stream, the one that I just demonstrated, and we're going to see if we can preview those streams. Okay, I've got live data. I'd previously had no connection to Kuffka. I turned on Kuffka, saw the data flowing from the Kuffka portal. I can preview the raw payload of a message that's coming live through that data stream to make sure I'm connecting to the correct stream and connecting that stream to the correct target. The preview looks good, although I do have a rather complex time stamp that I need to pass. Okay, the next step is I need to infer that from the stream that I selected based on that message payload the expected schema of that Kafka message. This actually helps us in the future. If someone modifies my underlying data systems, changes the schema, data fusion actually alert sends you an alert saying this table has been changed. The schema has changed. This stream is no longer active. This stream contains data that looks very different from what was expected. This inference on the schema happens all automatically, saving all the developers time. Moving on to the next section, I select my target object. The target, the object that I wish to integrate to is called wind turbine object. Uh wind turbine measurement. The one of those purple objects that I previewed before canonical and C3 language. You can think of that as a plug, a socket from which to integrate data into. So this is the socket into the wind turbine measurement. And these are the expected fields that the socket exposes that I want to integrate data into. I select this object. Next, I want to define a transform. There's multiple different types of transforms I can create here. For this demonstration, I'm going to be demon uh transforming using the field mapper and expression transformer. We can also define filters. So if I want to say data is coming in from facil wind wind turbine A and I want to apply a special transform from wind turbine A can filter apply a transform just for wind turbine A and I can apply a different filter and transform for wind turbine B even if all of that data is coming over the single data stream. I'm a bit lazy so I don't want to actually do all of the field mapping. So, I'm going to ask the AI to help me map these fields. And for the most part, this gets it very correct most of the time. This particular circumstance, I have a funky time stamp. My time stamp I need to apply a special treatment for, which I'm going to copy and update the timestamp. Time stamp transform looks good. And we have a reference of all of the different types of transforms we can apply directly from this interface. Other types of transforms we can perform. We can actually also write transforms in Python, JavaScript, your tool of choice. All of these transforms look good. So I'm going to click save. Behind the scenes, Data Fusion is actually modifying the codebase. Everything in C3, the sources, the transforms, the data pipelines are defined in code so that they're transportable between different uh clusters, environments, and so forth. So, I'm going to go over to my data model now. So, first I'm going to go over here to let it load. Okay, my stream is now connected and I have it mapped correctly. And then my data integration perspective, all of the pipelines are now configured. Two of which Jake configured. The last I just configured live. This is the particular object that I wanted to integrate into moment of truth. And we have live data. So previously I showed no data in this object. We have live data. This is not normal ordinary data. This is streaming data coming from a real vibrational sensor. Real sensors flowing through my Kafka broker that I connected to live. And that is data fusion. But that's actually not all of data fusion. This is a great start. Our C3 pre-built application defines 90% of the logic we need for our Gentig AI use case, but not all of the logic. We want to extend this data model by adding new objects to this data model. We don't want to just populate a data model. We want to build and extend the data model. I'm going to add a new object to the data model. Jake already configured Snowflake for me. What I'm going to do, the table in question, the data in question that I want to add to this object model that does not yet exist in the object model already exists in Snowflake. So, let's just add it. Going to get explore my Snowflake account. And I'm can now actually preview all of the tables in my data warehouse within the specific schema I've identified. I can search the tables in my Snowflake instance. I'm going to call select or preview. Click on wind turbine genai. Without even adding the data source, I can preview any and all of the data in my snowflake instance or any of my other data sources for that matter. You can switch this out with big query de data brick service now etc. Previewing enables me to select the right table before I bring it into my object model. I like this table so I'm going to select it. Click next. I can actually select multiple as well. Define the schema. I can add additional annot annotations and metadata to all fields if I don't have a system a metadata catalog already. when I'm building a Gentic AI platform to help the agent navigate the data model and perform the correct queries to the structured data within your data model. It's very h useful to provide additional details of what a specific field means. Field doesn't particularly know what mm means, but we know that means it's an abbreviation for vibration measurement. So, we want to provide as much detail as possible. And we can also provide change the column names and what they exist in our source system. Genai new object and click save. Okay. So we've now connected to a new table. There we go. Let's go see if we can find this new table over in the object model. There we go. This is the table that we just brought in live. So, we just modified the object model and added a net new table to this object model. What we've actually done here is we've taken a shortcut and virtualized this ob this object. So, we not don't need to clone this data into C3 this external tag. So the object model representation within data fusion provides a lot of details around what an object is associated with. In this instance is showing that this is an external table that we've connected to and I should be able to view the details coming straight through from snowflake. So that is data fusion. Data Fusion is updating the metadata of so updating the codebase of this application. Data Fusion has the ability to add new objects to the object model, create new relationships, virtualize data. You can upload a file to create a new object or you can define a more advanced object based on your needs. any relationship, any flavor of object, be it a vector store object to store your embeddings, be it a key value object to store time series or ver or relationships between relational data. It's updating the metadata. And if we brought up VS Code, we can actually view this metadata and continue our development in our high code development tools. In summary, Jake and I started one of C3'sund what 31 C 131 pre-built applications that got us 90% there with the business logic we wanted to introduce as part of our new Aentic AI use case. We explored the object model to onboard to the the pre-built object model to onboard to certain details such as showing which objects we needed to integrate data into versus which ones are populated from downstream data processing tasks. We configured live data integrations showcasing integrating data live from Google blob storage live from Kuffka where we actually configured that connection end to end with live credentials. We extended the object model by actually adding ex ex net new tables to the uh object model of the pre-existing application thus modifying it for our own needs. In this instance, we added a new table based on virtualization from Snowflake. And we can reflect on these changes by interchanging between the visual tooling we just demonstrated to the Highode tools VS Code extension or our brand new in browser VS Code offer where we can now just modify code directly in the browser using in browser VS Code which is huge for security by the way. None of your code ever needs to land on any of your developers laptops. We believe data fusion is a gamecher for our agentic AI platform. Omnimodal data architecture is not sufficient. It's a requirement but not sufficient. the ability to visually monitor, manage, change your object model, your integrations, and validate your data on the fly visually through the myriad of data sources that are coming in from your business systems. It's critical for the future of Aentic AI systems. On that note, thank you so much for uh for coming today. I know it's been a huge day. We've got a few few moments for Jake and myself to answer questions. And again, thank you so much. And we welcome you also to vis visit our C3 Agentic AI. We have two booths with Shay and uh Josh, myself and a couple other product managers um in the AI marketplace. So open for questions. Can I drop the mic now? Drop the mic. Come on. Thank you. Is that on? Can you hear me? Yeah. Uh did I hear you say spatial data was one of those like a point cloud? So you guys are able to to bring that in and potentially render that in in an application from a perspective. We can uh we we have a couple of customers. There's one in Europe that actually presented at Transform last year that uh is a leader in collecting drone visual data and that drone visual data uh can be modeled as part of C3's object model. Point cloud data is very large. So you typically store that point cloud data in blob storage but then generate huge amounts of metadata on that point cloud that then goes either into time series or uh relational stores so that you can access it when you need and of course now we can create embeddings on point cloud. So this point cloud what is it? It actually from a structure standpoint is most similar to a tree. So I'm going to classify this as a tree using these new agentic uh search approaches. Well, thank you all for joining this session. Really appreciate you coming and enjoy the rest of transform. We'll be at the AI marketplace. \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0aaa0c4-a344-48a9-a6d4-992ba2e08c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{get_youtube_video_id(video_url)}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(test_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
